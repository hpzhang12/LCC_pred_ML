{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da244e9",
   "metadata": {
    "id": "2da244e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/hpzhang/tools/anaconda3/envs/geocat/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b142cbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12868,
     "status": "ok",
     "timestamp": 1651875847555,
     "user": {
      "displayName": "Haipeng Zhang",
      "userId": "14783312206665290239"
     },
     "user_tz": 240
    },
    "id": "9b142cbd",
    "outputId": "de91b5d8-436b-4a3b-e70b-45f6c0cac8eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5350237"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = pd.read_pickle(\"/glade/work/hpzhang/LCC_pred/data/data_monthly.pkl\").dropna()\n",
    "df  = ff.drop(columns=['lat', 'lon', 'lsm', 'T1000', 'T700', 'EIS', 'ECTEI','ELF','SST','AOD'])\n",
    "df = df[df.index.year.isin(np.arange(2003,2019))]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e07c8e9-8138-4c8a-8b29-d10af81b024e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCF</th>\n",
       "      <th>TH1000</th>\n",
       "      <th>TH850</th>\n",
       "      <th>TH700</th>\n",
       "      <th>RH1000</th>\n",
       "      <th>RH850</th>\n",
       "      <th>RH700</th>\n",
       "      <th>Q1000</th>\n",
       "      <th>Q850</th>\n",
       "      <th>Q700</th>\n",
       "      <th>U1000</th>\n",
       "      <th>U700</th>\n",
       "      <th>OMEGA500</th>\n",
       "      <th>OMEGA700</th>\n",
       "      <th>PWV</th>\n",
       "      <th>LH</th>\n",
       "      <th>SH</th>\n",
       "      <th>Tadv</th>\n",
       "      <th>dQ</th>\n",
       "      <th>LTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-15</th>\n",
       "      <td>0.590822</td>\n",
       "      <td>273.145630</td>\n",
       "      <td>277.822327</td>\n",
       "      <td>286.950775</td>\n",
       "      <td>85.577278</td>\n",
       "      <td>84.145813</td>\n",
       "      <td>69.974464</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>3.637893</td>\n",
       "      <td>6.459276</td>\n",
       "      <td>0.004265</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>8.286732</td>\n",
       "      <td>-14.891875</td>\n",
       "      <td>-1.580903</td>\n",
       "      <td>0.898143</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>13.805145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-15</th>\n",
       "      <td>0.590822</td>\n",
       "      <td>273.192474</td>\n",
       "      <td>277.799255</td>\n",
       "      <td>286.895844</td>\n",
       "      <td>85.665604</td>\n",
       "      <td>84.507431</td>\n",
       "      <td>69.732834</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>3.618882</td>\n",
       "      <td>6.377827</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>8.276699</td>\n",
       "      <td>-13.840185</td>\n",
       "      <td>-0.886921</td>\n",
       "      <td>-0.020427</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>13.703369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-15</th>\n",
       "      <td>0.556442</td>\n",
       "      <td>273.239288</td>\n",
       "      <td>277.803558</td>\n",
       "      <td>286.847046</td>\n",
       "      <td>85.945564</td>\n",
       "      <td>84.507431</td>\n",
       "      <td>69.224571</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>3.703815</td>\n",
       "      <td>6.273440</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.008408</td>\n",
       "      <td>8.276699</td>\n",
       "      <td>-13.721111</td>\n",
       "      <td>-0.987361</td>\n",
       "      <td>-0.006477</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>13.607758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-15</th>\n",
       "      <td>0.556442</td>\n",
       "      <td>273.258575</td>\n",
       "      <td>277.851196</td>\n",
       "      <td>286.802826</td>\n",
       "      <td>86.460487</td>\n",
       "      <td>84.855713</td>\n",
       "      <td>69.139580</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>3.733388</td>\n",
       "      <td>6.172708</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>8.293421</td>\n",
       "      <td>-12.907546</td>\n",
       "      <td>-0.686019</td>\n",
       "      <td>0.069008</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>13.544250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-15</th>\n",
       "      <td>0.584355</td>\n",
       "      <td>273.276489</td>\n",
       "      <td>277.882935</td>\n",
       "      <td>286.755585</td>\n",
       "      <td>86.692123</td>\n",
       "      <td>85.037354</td>\n",
       "      <td>69.027931</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>3.706906</td>\n",
       "      <td>6.052912</td>\n",
       "      <td>0.009849</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>8.286732</td>\n",
       "      <td>-12.451134</td>\n",
       "      <td>-0.850394</td>\n",
       "      <td>-1.276983</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>13.479095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LCF      TH1000       TH850       TH700     RH1000  \\\n",
       "time                                                                  \n",
       "2003-01-15  0.590822  273.145630  277.822327  286.950775  85.577278   \n",
       "2003-01-15  0.590822  273.192474  277.799255  286.895844  85.665604   \n",
       "2003-01-15  0.556442  273.239288  277.803558  286.847046  85.945564   \n",
       "2003-01-15  0.556442  273.258575  277.851196  286.802826  86.460487   \n",
       "2003-01-15  0.584355  273.276489  277.882935  286.755585  86.692123   \n",
       "\n",
       "                RH850      RH700     Q1000      Q850      Q700     U1000  \\\n",
       "time                                                                       \n",
       "2003-01-15  84.145813  69.974464  0.003216  0.002045  0.001219  3.637893   \n",
       "2003-01-15  84.507431  69.732834  0.003221  0.002052  0.001191  3.618882   \n",
       "2003-01-15  84.507431  69.224571  0.003238  0.002052  0.001163  3.703815   \n",
       "2003-01-15  84.855713  69.139580  0.003261  0.002063  0.001153  3.733388   \n",
       "2003-01-15  85.037354  69.027931  0.003274  0.002071  0.001152  3.706906   \n",
       "\n",
       "                U700  OMEGA500  OMEGA700       PWV         LH        SH  \\\n",
       "time                                                                      \n",
       "2003-01-15  6.459276  0.004265  0.005796  8.286732 -14.891875 -1.580903   \n",
       "2003-01-15  6.377827  0.002914  0.010119  8.276699 -13.840185 -0.886921   \n",
       "2003-01-15  6.273440  0.001923  0.008408  8.276699 -13.721111 -0.987361   \n",
       "2003-01-15  6.172708  0.005346  0.004445  8.293421 -12.907546 -0.686019   \n",
       "2003-01-15  6.052912  0.009849  0.000932  8.286732 -12.451134 -0.850394   \n",
       "\n",
       "                Tadv        dQ        LTS  \n",
       "time                                       \n",
       "2003-01-15  0.898143  0.001997  13.805145  \n",
       "2003-01-15 -0.020427  0.002030  13.703369  \n",
       "2003-01-15 -0.006477  0.002075  13.607758  \n",
       "2003-01-15  0.069008  0.002108  13.544250  \n",
       "2003-01-15 -1.276983  0.002122  13.479095  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093a048c-bbd1-44b8-8dce-0fb839759a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = df.drop(columns=['Tadv', 'dQ', 'LTS'])\n",
    "data = df\n",
    "index_train = data.index.year.isin(np.arange(2003,2015))\n",
    "index_test  = data.index.year.isin(np.arange(2015,2019))\n",
    "data_train = data[index_train]\n",
    "data_test  = data[index_test]\n",
    "\n",
    "X_train, y_train = data_train.iloc[:,1:], data_train.iloc[:,0]\n",
    "X_test, y_test   = data_test.iloc[:,1:], data_test.iloc[:,0]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2b4362-ce40-40d6-ae7c-fd00cc6d1875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import RandomizedSearchCV\\n\\nparams = { \\'max_depth\\': [5, 6, 10],\\n           \\'learning_rate\\': [0.01, 0.1, 0.2, 0.3],\\n           \\'subsample\\': np.arange(0.5, 1.0, 0.1),\\n           \\'colsample_bytree\\': np.arange(0.4, 1.0, 0.1),\\n           \\'colsample_bylevel\\': np.arange(0.4, 1.0, 0.1),\\n           \\'n_estimators\\': [200, 500, 1000]}\\nxgbr = xgb.XGBRegressor(tree_method=\\'gpu_hist\\', \\n                        eval_metric=mean_squared_error,\\n                        gpu_id=0, seed = 1001, n_jobs=-1)\\nclf = RandomizedSearchCV(estimator=xgbr,\\n                         param_distributions=params,\\n                         scoring=\\'neg_mean_squared_error\\',\\n                         n_iter=50,\\n                         verbose=3,\\n                         cv=3)\\nclf.fit(X_train_scaled, y_train)\\nprint(\"Best parameters:\", clf.best_params_)\\nprint(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\\nprint(\"Lowest MSE: \", (-clf.best_score_))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = { 'max_depth': [5, 6, 10],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [200, 500, 1000]}\n",
    "xgbr = xgb.XGBRegressor(tree_method='gpu_hist', \n",
    "                        eval_metric=mean_squared_error,\n",
    "                        gpu_id=0, seed = 1001, n_jobs=-1)\n",
    "clf = RandomizedSearchCV(estimator=xgbr,\n",
    "                         param_distributions=params,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         n_iter=50,\n",
    "                         verbose=3,\n",
    "                         cv=3)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\n",
    "print(\"Lowest MSE: \", (-clf.best_score_))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b58f96-101b-4050-9529-32467e327def",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import GridSearchCV\\n\\nparams = { \\'max_depth\\': [5, 6, 7, 8, 9, 10],\\n#           \\'learning_rate\\': [0.01, 0.1, 0.2, 0.3],\\n#           \\'subsample\\': np.arange(0.5, 1.0, 0.1),\\n#           \\'colsample_bytree\\': np.arange(0.4, 1.0, 0.1),\\n#           \\'colsample_bylevel\\': np.arange(0.4, 1.0, 0.1),\\n           \\'n_estimators\\': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]}\\nxgbr = xgb.XGBRegressor(tree_method=\\'gpu_hist\\', \\n                        eval_metric=mean_squared_error,\\n                        gpu_id=0, seed = 1001, n_jobs=-1)\\n\\nclf = GridSearchCV(estimator=xgbr, \\n                   param_grid=params,\\n                   scoring=\\'neg_mean_squared_error\\', \\n                   verbose=3,\\n                   cv=5)\\nclf.fit(X_train_scaled, y_train)\\nprint(\"Best parameters:\", clf.best_params_)\\nprint(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\\nprint(\"Lowest MSE: \", (-clf.best_score_))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'max_depth': [5, 6, 7, 8, 9, 10],\n",
    "#           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "#           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "#           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "#           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]}\n",
    "xgbr = xgb.XGBRegressor(tree_method='gpu_hist', \n",
    "                        eval_metric=mean_squared_error,\n",
    "                        gpu_id=0, seed = 1001, n_jobs=-1)\n",
    "\n",
    "clf = GridSearchCV(estimator=xgbr, \n",
    "                   param_grid=params,\n",
    "                   scoring='neg_mean_squared_error', \n",
    "                   verbose=3,\n",
    "                   cv=5)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\n",
    "print(\"Lowest MSE: \", (-clf.best_score_))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bb4035b-7064-47e2-a428-3b2df027bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a binary pickle file \n",
    "#f = open(\"cv_results.pkl\",\"wb\")\n",
    "#pickle.dump(clf.cv_results_, f)\n",
    "#f.close()\n",
    "\n",
    "#f = open(\"/glade/u/home/hpzhang/work/LCC_pred/optimize/cv_results.pkl\",'rb')\n",
    "#cv_res = pickle.load(f)\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bd6284f-04f5-404f-a0e0-8af81656722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse=(-cv_res[\"mean_test_score\"])**(1/2.0)\n",
    "#std=cv_res[\"std_test_score\"]\n",
    "#plt_dat=pd.DataFrame(rmse.reshape(-1,10), index=np.arange(5,11), columns=np.arange(100,1001,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e721ef5-0187-4e49-a3d3-0b60575d4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f, ax = plt.subplots(figsize=(20, 10))\n",
    "#ax = sns.heatmap(plt_dat, linewidth=0.5,\n",
    "#                cmap=\"YlGnBu_r\",\n",
    "#                annot=True,\n",
    "#                fmt='5.5f')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f29443-35a1-4762-875d-825c59f0b155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | colsam... | learni... | max_depth | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.004008\u001b[0m | \u001b[0m 0.6531  \u001b[0m | \u001b[0m 0.6325  \u001b[0m | \u001b[0m 0.2041  \u001b[0m | \u001b[0m 4.722   \u001b[0m | \u001b[0m 120.8   \u001b[0m | \u001b[0m 0.5979  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.003341\u001b[0m | \u001b[95m 0.6764  \u001b[0m | \u001b[95m 0.6116  \u001b[0m | \u001b[95m 0.6174  \u001b[0m | \u001b[95m 5.322   \u001b[0m | \u001b[95m 868.2   \u001b[0m | \u001b[95m 0.5206  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.003511\u001b[0m | \u001b[0m 0.7441  \u001b[0m | \u001b[0m 0.9604  \u001b[0m | \u001b[0m 0.118   \u001b[0m | \u001b[0m 4.644   \u001b[0m | \u001b[0m 523.1   \u001b[0m | \u001b[0m 0.5636  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-0.003064\u001b[0m | \u001b[95m 0.9179  \u001b[0m | \u001b[95m 0.6096  \u001b[0m | \u001b[95m 0.2472  \u001b[0m | \u001b[95m 6.552   \u001b[0m | \u001b[95m 868.2   \u001b[0m | \u001b[95m 0.8313  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.003025\u001b[0m | \u001b[95m 0.8997  \u001b[0m | \u001b[95m 0.8853  \u001b[0m | \u001b[95m 0.1618  \u001b[0m | \u001b[95m 6.971   \u001b[0m | \u001b[95m 870.0   \u001b[0m | \u001b[95m 0.9239  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.003059\u001b[0m | \u001b[0m 0.7617  \u001b[0m | \u001b[0m 0.9691  \u001b[0m | \u001b[0m 0.2777  \u001b[0m | \u001b[0m 6.739   \u001b[0m | \u001b[0m 874.5   \u001b[0m | \u001b[0m 0.5925  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.004326\u001b[0m | \u001b[0m 0.5772  \u001b[0m | \u001b[0m 0.5177  \u001b[0m | \u001b[0m 0.9992  \u001b[0m | \u001b[0m 6.321   \u001b[0m | \u001b[0m 879.1   \u001b[0m | \u001b[0m 0.5998  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.003372\u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 0.6569  \u001b[0m | \u001b[0m 0.6109  \u001b[0m | \u001b[0m 3.7     \u001b[0m | \u001b[0m 873.1   \u001b[0m | \u001b[0m 0.7883  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.003122\u001b[0m | \u001b[0m 0.9889  \u001b[0m | \u001b[0m 0.559   \u001b[0m | \u001b[0m 0.08121 \u001b[0m | \u001b[0m 6.976   \u001b[0m | \u001b[0m 864.5   \u001b[0m | \u001b[0m 0.9333  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.003157\u001b[0m | \u001b[0m 0.5623  \u001b[0m | \u001b[0m 0.6982  \u001b[0m | \u001b[0m 0.07124 \u001b[0m | \u001b[0m 6.489   \u001b[0m | \u001b[0m 859.6   \u001b[0m | \u001b[0m 0.6043  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.00349 \u001b[0m | \u001b[0m 0.5802  \u001b[0m | \u001b[0m 0.8154  \u001b[0m | \u001b[0m 0.9628  \u001b[0m | \u001b[0m 3.268   \u001b[0m | \u001b[0m 855.5   \u001b[0m | \u001b[0m 0.8442  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.003388\u001b[0m | \u001b[0m 0.7803  \u001b[0m | \u001b[0m 0.9935  \u001b[0m | \u001b[0m 0.3238  \u001b[0m | \u001b[0m 3.052   \u001b[0m | \u001b[0m 862.2   \u001b[0m | \u001b[0m 0.9788  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.003517\u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 0.9519  \u001b[0m | \u001b[0m 0.2702  \u001b[0m | \u001b[0m 4.909   \u001b[0m | \u001b[0m 304.5   \u001b[0m | \u001b[0m 0.8542  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.003277\u001b[0m | \u001b[0m 0.7781  \u001b[0m | \u001b[0m 0.7983  \u001b[0m | \u001b[0m 0.5875  \u001b[0m | \u001b[0m 4.839   \u001b[0m | \u001b[0m 692.5   \u001b[0m | \u001b[0m 0.6237  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.003525\u001b[0m | \u001b[0m 0.6098  \u001b[0m | \u001b[0m 0.8458  \u001b[0m | \u001b[0m 0.7631  \u001b[0m | \u001b[0m 6.899   \u001b[0m | \u001b[0m 872.6   \u001b[0m | \u001b[0m 0.7423  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.003044\u001b[0m | \u001b[0m 0.7164  \u001b[0m | \u001b[0m 0.847   \u001b[0m | \u001b[0m 0.2248  \u001b[0m | \u001b[0m 6.423   \u001b[0m | \u001b[0m 862.0   \u001b[0m | \u001b[0m 0.819   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.003143\u001b[0m | \u001b[0m 0.6174  \u001b[0m | \u001b[0m 0.6379  \u001b[0m | \u001b[0m 0.2121  \u001b[0m | \u001b[0m 5.093   \u001b[0m | \u001b[0m 864.4   \u001b[0m | \u001b[0m 0.5173  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.003663\u001b[0m | \u001b[0m 0.7842  \u001b[0m | \u001b[0m 0.5157  \u001b[0m | \u001b[0m 0.9919  \u001b[0m | \u001b[0m 3.677   \u001b[0m | \u001b[0m 689.0   \u001b[0m | \u001b[0m 0.7542  \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pbounds = {\n",
    "    'learning_rate': (0.01, 1.0),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'max_depth': (3,7),\n",
    "    'subsample': (0.5, 1.0),  \n",
    "    'colsample_bytree': (0.5, 1.0), \n",
    "    'colsample_bylevel': (0.5, 1.0)}\n",
    "\n",
    "def xgboost_hyper_param(learning_rate,\n",
    "                        n_estimators,\n",
    "                        max_depth,\n",
    "                        subsample,\n",
    "                        colsample_bytree,\n",
    "                        colsample_bylevel):\n",
    "\n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    clf = xgb.XGBRegressor(tree_method='gpu_hist', \n",
    "                        eval_metric=mean_squared_error,\n",
    "                        gpu_id=0, seed = 1001, n_jobs=-1,\n",
    "                        learning_rate=learning_rate,\n",
    "                        n_estimators=n_estimators,\n",
    "                        max_depth=max_depth,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        colsample_bylevel=colsample_bylevel)\n",
    "\n",
    "    return np.mean(cross_val_score(clf, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgboost_hyper_param,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1001,\n",
    ")\n",
    "\n",
    "optimizer.maximize(n_iter=15, init_points=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "261de9c8-8646-4c91-961c-ab50d6540d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bylevel': 0.8996518880817399,\n",
       " 'colsample_bytree': 0.8853387899201755,\n",
       " 'learning_rate': 0.16184400108442132,\n",
       " 'max_depth': 6.970737464733581,\n",
       " 'n_estimators': 869.9900903438686,\n",
       " 'subsample': 0.9239287537315828}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d1c560-09e2-4b74-bdef-b233c43f6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2870260-b6c0-4320-9c01-9a2ebaa30282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, res in enumerate(optimizer.res):\n",
    "#    print(\"Iteration {}: \\n\\t{}\".format(i, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8195fc-0700-4c44-8e86-d73356f7a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_monthly.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-geocat]",
   "language": "python",
   "name": "conda-env-anaconda3-geocat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
